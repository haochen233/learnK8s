本章内容涵盖
- 了解在一个典型应用中会出现哪些Kubernetes的资源
- 添加pod启动后和停止前的生命周期钩子
- 在kubernetes中如何方便地管理应用
- 在pod 中使用init容器
  
---
### 17.1 集中一切资源
一个**典型的应用**包含了一个或多个**Deploy**或**sts**对象，这些对象中包含了一个或多个容器的**pod模板**，每个容器都有一个**存活探针**，并且为**容器提供的服务** （如果有的话）提供**就绪探针**。

提供服务的 **pod** 是通过一个或者多个**服务**来暴露自己的。当需要从集群外访问这些服务的时候，要么将这些服务配置为 **LoadBalancer** 或者 **NodePort** 类型的服务，要么通过 **Ingress** 资源来开放服务。

pod模板通常会引用两种类型的**私密凭据（Secret）**。一种是从私有镜像仓库拉取镜像时使用的；另一种是pod中运行的进程直接使用的。

私密凭据本身通常不是应用 manifest 的一部分，因为它们不是由应用开发者来配置，而是由运维团队来配置的。私密凭据通常会被分配给 **ServiceAccount** ， 然后**ServiceAccount** 会被分配给每个单独的 **pod** 。

一个应用还包含一个或者多个**ConfigMap**对象，可以用它们来初始化环境变 量， 或者在 **pod** 中 以 **configMap** 卷来挂载。有一些 pod 会使用额外的卷，例如**emptyDir**或**gitRepo**卷，而需要**持久化存储**的**pod**则需要**PersistentVolumeClaim卷**，

**PersistentVolumeClaim** 也是一个应用 **manifest** 的一部分，而被 **PersistentVolumeClaim** 所引用的 **StorageClass**（**PersistentVolume**）则是由系统管理员事先创建的。

在某些情况下，一个应用还需要使用**任务（Jobs）**和**定时任务（CronJobs）**，**守护进程集（DaemonSet ）**通常不是应用部署的一部分，但是通常由系统管理员创建，以在全部或者部分节点上运行系统服务。

**水平pod扩容器（HorizationPodAutoScaler）**可以由开发者包含在应用 manifest 中或者后续由运维团队添加到系统中。集群管理员还会创建**LimitRange**和**ResourceQuota**对象，以控制每个pod和所有pod的计算资源使用情况。

在应用部署后，各种 **Kubernetes 控制器**会自动创建其他的对象。其中包括**端点控制器** （Endpoint controller ）创建的服务端点（Endpoint ）对象，**部署控制器**（Deployment controller ）创建的 ReplicaSet 对象，以及由 ReplicaSet （ 或者 Job 、CronJob 、 Statefu!Set 、 DaemonSet ）创建的实际的 pod 对象。

---
### 17.2 了解pod的生命周期

我们之前说过，可以将 pod 比作只运行单个应用的虚拟机。尽管在 pod 中运行的应用和虚拟机中运行的应用没什么不同，但是还是存在显著的差异。 其中一个例子就是 pod 中运行的应用随时可能会被杀死，因为 Kubernetes 需要将这个 pod 调度到另外一个节点，或者是请求缩容。我们接下来将探讨这方面的内容。

---
### 17.2.1 应用必须预料到会被杀死或者重新调度
在 Kubernetes 之外，运行在虚拟机中的应用很少会被从一台机器迁移到另外一台。当一个操作者迁移应用的时候，他们可以重新配置应用并且于动检查应用是否在新的位置正常运行。借助于 Kubernetes ， 应用可以更加频繁地进行自动迁移而无须人工介入，也就是说没有人会再对应用进行配置并且确保它们在迁移之后能够正常运行。这就意味着应用开发者必须允许他们的应用可以被相对频繁地迁移。

---
### 预料到本地IP和主机名会发生变化
当一个 pod 被杀死井且在其他地方运行之后（技术上来讲是一个新的 pod 替换了旧的 pod ，旧 pod 没有被迁移），它不仅拥有了一个新的 IP 地址还有了一个新的名称和主机名。

大部分无状态的应用都可以处理这种场景同时不会有不利的影响，但是有状态服务通常不能。

StatefulSet 会保证在将应用调度到新的节点并启动之后，它可以看到和之前一样的主机名和持久化状态。当然 pod 的 IP 还是会发生变化，应用必须能够应对这种变化。 因此应用开发者在一个集群应用中不应该依赖成员的四地址来构建彼此的关系，另外如果使用主机名来构建关系，必须使用 StatefulSet 。

---
### 预料到写入磁盘的数据会消失
还有一件事情需要记住的是，在应用往磁盘写入数据的情况下， 当应用在新的pod 中启动后这些数据可能会丢失，**除非你将持久化的存储挂载到应用的数据写入路径&**。在 pod 被重新调度的时候，数据丢失是一定的，但是即使在没有调度的情况下，写入磁盘的文件仍然会丢失。

单个容器可能因为各种原因被重启，例如进程崩溃了，例如存活探针返回失败了，或者是因为节点内存逐步耗尽，进程被 OOMKiller 杀死了 。当上述情况发生时，pod还是一样的，但是容器确实全新的了，kubelet不会创建一个容器运行多次，而是会重新创建一个容器。

---
### 使用存储卷来跨容器持久化数据
---
当 pod 的容器重启后，本例中的应用仍然需要执行有大量计算过程的启动程序。这个或许不是你所期望的。 为了保证这种情况下数据不丢失，你需要至少使用一个pod 级别的卷（如emptyDir，挂载到pod的容器上）。 因为卷的存在和销毁与 pod 生命周期是一致的， 所以新的容器将可以重用之前容器写到卷上的数据。

有时候使用存储卷来跨容器存储数据是个好办法，但是也不总是如此。万一由于数据损坏（依赖卷上的数据）而导致新创建的进程再次崩溃昵？这会导致一个持续性的循环崩溃（pod会提示 CrashLoopBackOff状态）。 

如果不使用存储卷的话，新的容器会从零开始启动，并且很可能不会崩溃。 使用存储卷来跨容器存储数据是把双刃剑。 你需要仔细思考是否使用它们。

---
### 17.2.2 重新调度死亡的或者部分死亡的 pod
如果一个 pod 的容器一直处于崩溃状态， Kubelet 将会一直不停地重启它们。每次重启的时间间隔将会以指数级增加， 直到达到 5 分钟。 在这个 5 分钟的时间间隔中，pod 基本上是死亡了 ，因为它们的容器进程没有运行。 公平来讲，如果是个多容器的 pod ， 其中的一些容器可能是正常运行的，所以这个 pod 只是部分死亡了。 但是如果 pod 中仅包含一个容器，那么这个 pod 是完全死亡的而且己经毫无用处了，因为里面己经没有进程在运行了。

replicaSet 本身并不关心 pod 是否处于死亡状态，它只关心 pod 的数量是否匹配期望的副本数量，在这种情况下，副本数量确实是匹配的。

容器将会每5分钟重启一次，在这个过程中Kubernetes期望崩溃的底层原因会被解决。这个机制依据的基本原理就是将pod重新调度到其他节点通常并不会解决崩溃的问题，因为应用运行在容器的内部，所有的节点理论上应该都是相同的。虽然上面的情况并不总是如此，但是大多数情况下都是这样。

---
### 17.2.3 以固定顺序启动pod
pod中运行的应用和手动运行的应用之间的另外一个不同就是运维人员在手动
部署应用的时候知道应用之间的依赖关系，这样他们就可以按照顺序来启动应用。

---
### 了解pod是如何启动的
Kubernetes API服务器确实是按照YAML或者JSON文件中定义的对象的顺序来进行处理的，但是仅仅意味着它们在被写入到 etcd的时候是有顺序的。无法确保pod会按照那个顺序启动。

但是你可以阻止一个主容器的启动，直到它的预置条件被满足。这个是通过在pod中包含一个叫作init的容器 来实现的。

### init 容器介绍
除了常规的容器，pod还可以包括init容器。如容器名所示，它们 可以用来初始化pod, 这通常意味着向容器的存储卷中写入数据，然后将这个存储卷挂载到主容器中。

一个pod可以拥有任意数量的init容器。init容器是顺序执行的， 并且仅当最后一个init容器执行完毕才会去启动主容器。换句话说，init容器也可以用来延迟pod的主容器的启动。

创建一个init容器：  
```yaml
...
spec:
  initContainers:
  - name: i1
    image: init_cont:1.0
    command: [直到服务器准备好后，才可启动客户端主容器]
```

---
### 17.2.4 增加生命周期钩子
我们已经讨论了如果使用 init容器来介入pod的启动过程， 另外pod 还允许你
定义两种类型的生命周期钩子：  
- 启动后（Post-start）钩子
- 停止前（Pre-stop）钩子

这些生命周期 的钩子是基于每个容器来指定的，和init容器 不同的是 ，init容器是应用到整个pod。这些钩子，如它们的名字所示 ，是在容器启动后和停止前执行的。

生命周期钩子与存活探针和就绪探针相似的是它们都 可以：  
- 在容器内部执行一个命令 （exec字段）
- 向URL发送HTTP GET 请求

---
### 使用启动后容器生命周期钩子
启动后钩子是在容器的主进程启动之后立即执行的。可以用它在应用启动时做一些额外的工作。当然，如果你是容器中运行的应用的开发者，可以在应用的代码中加入这些操作。但是，如果你在运行一个其他人开发的应用，大部分情况下并不想（或者无法）修改它的源代码。启动后钩子可以让你在不改动应用的情况下，运行一些额外的命令。

在钩子执行完毕之前，容器会一直停留在Waiting 状态，其原因是ContainerCreating。

因此，pod的状态会是Pending而不是Running。如果钩子运行失败或者返回了非零的状态码，主容器会被杀死。

包含启动后生命周期钩子的pod： post-start-hook：  
```yaml
...
spec:
  containers:
  - name: serv
    image: go_serv:2.0
    ...
    lifecycle:
      postStart:
        exec:
          command: ["sh", "-c", "echo 'hook will fail exit code 20';sleep 10; exit 20"]

```
典型情况下，我们并不会像这样来执行命令，而是通过存储在容器镜像中shell脚本或二进制可执行文件来运行。

憾的是， 如果钩子程序启动的进程将日志输出到标准输出终端， 你将无法在任何地方看到它们。 这样就会导致调试生命周期钩子程序非常痛苦。

如果钩子程序失败了， 你仅仅会在pod的事件中看到一个FaledPostStatHook 的告警信息（可以通过命令kubectl describe  pod 来查看）

稍等一会儿， 你就可以看到更多关于钩子为什么失败的信息。

基于命令的启动后钩子输出到标准输出终端和错误输出终端的内容在任何地方都不会记录， 因此你或许想把钩子程序的进程输出记录到容器的文件系统文件中，这样你可以通过如下的命令来查看文件的内容。

如果容器因为各种原因重启了（包括由于钩子执行失败导致的），这个文件在你能够查看之前就消失了。 这种情况下， 可以通过给容器挂载一个emptyDir卷，并且让钩子程序向这个存储卷写入内容来解决。（卷与pod生命周期一致）。

---
### 使用停止前生命周期钩子
停止前钩子是在容器被终止之前立即执行的。 当一个容器需要终止运行的时候Kubelet在配置了停止前钩子的时候就会执行这个停止前钩子，并且仅在执行完钩子程序后才会向容器进程发送SIGTERM信号（如果这个进程没有优雅地终止运行，则会被杀死。

preStop与postStart用法类似。

和启动后钩子不同的是，无论停止前钩子执行是否成功容器都会被终止。

如果停止前钩子执行失败了，你会在pod的时间中看到PreStopHookError，，但是因为pod不久就会被删除了（毕竟是pod的删除动作触发的停止前钩子的执行）你或许都看不到停止前钩子执行失败了。

> 提示：如果停止前钓子的成功执行对系统的行为很重要，请确认这个钓子是否成
功执行了。

---
### 在应用没有收到SIGTERM信号时使用停止前钩子



---
### 了解生命周期钩子是针对容器而不是pod
强调一下的是这些生命周期的钩子是针对容器而不是pod的。 你不应该使用停止前钩子来运行那些需要在pod终止的时候执行的操作。 原因是停止前钩子只会在容器被终止前调用（大部分可能是因为存活探针失败导致的终止）。

---
### 17.2.5 了解pod的关闭
pod的关闭是通过API服务器删除pod的对象来触发的。 当接收到HTTP DELETE请求后， API服务器还没有删除pod对象， 而是给pod设置一个deletionTimessamp值。拥有 deletionTimeStamp的pod就开始停止了。

当 kubelet意识到需要终止pod的时候，它开始终止pod中的每个容器。kubelet意识到需要终止pod的时候，它开始终止pod中的每个容器。kubelet会给每个容器一定的时间来优雅的停止。这个时间叫做终止宽限期（Termination Grace Period），每个pod可以单独配置。在终止进程开始之后，计时器就开始计时，接着按照顺序执行以下事件：  
1. 执行停止前钩子（如果配置了话），等待它执行完毕
2. 向容器的主进程发送SIGTERM 信号
3. 等待容器优雅的关闭或者等待终止宽限期超时（Termination grace period）
4. 如果容器主进程没有优雅地关闭，使用SIGKILL 信号强制终止进程


---
### 指定终止宽限期
可以通过指定pod.spec.terminationGracePeriodSeconds字段设置。默认是30秒。

> 提示 你应该将终止宽限时间设置得足够长， 这样你的容器进程才可以在这个时间段内完成清理工作。

在删除pod时，可以在kl delete 命令中覆盖manifest中指定的终止宽限期。用 --grace-period=5 ，让kubectl 等待5秒钟，让pod自行关闭。

>在使用这个选项的时候需要注意， 尤其是StatefulSet的pod。 StatefulSet控制器会非常小心地避免在同一时间运行相同pod的两个实例（两个pod拥有相同的序号、名称， 并且挂载到相同的PersistentVolume)。强制删除一个pod会导致控制器不会等待被删的pod里面的容器完成关闭就创建一个替代的pod。 换句话说， 相同pod的两个实例可能在同一时间运行， 这样会导致有状态的集群服务工作异常。 只有在确认pod不会再运行， 或者无法和集群中的其他成员通信（可以通过托管pod的节点网络连接失败并且无法重连来确认）的清况下再强制删除有状态的pod。

---
### 在应用中合理的处理容器关闭操作
应用应该通过启动关闭流程来响应S工GTERM信号， 并且在流程结束后终止运行。 除了处理SIGTERM信号， 应用还可以通过停止前钩子 来收到关闭通知。 在这两种情况下， 应用只有固定的时间来干净地终止运行 。

但是如果你无法预测应用需要多长时间来干净地终止运行怎么办呢？例如，假设你的应用是一个分布式数据存储。 在缩容的时候， 其中一个pod的实例会被删除然后关闭 。 在这个关闭的过程中， 这个pod需要将它的数据迁移到其他存活的pod上面以确保数据不会丢失。 那么这个pod是否应该在接收到终止信号的时候就开始迁移数据（无论是通过SIGTERM信号还是停止前钩子）？

完全不是！这种做法是不推荐的，理由至少有两点：   
- 一个容器终止运行并不代表整个pod被终止了
- 你无法保证这个关闭流程能够在进程被杀死之前执行。

---
### 将重要的关闭流程替换为专注于关闭流程的 pod
如何确认一个必须运行完毕的重要的关闭流程真的运行完毕了呢（例如， 确认一个pod的数据成功 迁移到了另外一个pod) ? 

一个解决方案是让应用（在接收到终止信号的时候）创建一个新的Job资源，

因此， 当你在使用 Statefu!Set的时候或许想运行一个数据迁移的pod为了避免应用在升级过程中出现数据迁移， 专门用于数据迁移的pod可以在数据迁移之前配置一个等待时间，

> 使用专门的pod来迁移数据

---
## 17.3 确保所有的客户端请求都得到了妥善处理
如果你在pod.spec中没有指定就绪探针， 那么pod总是被认为是准备好了的。当第一个kube-proxy在它的节点上面更新了iptables规则之后， 并且第一个客户端 pod 开始连接服务的时候， 这个默认被认为是准备好了的pod 几乎会立即开始接收请求。如果你的应用这个时候还没有准备好接收连接， 那么所有的客户端都会看到 “连接被拒绝”一类的错误信息

你需要做的是当且仅当你的应用**准备好**处理进来的请求的时候， 才去让就绪探针返回成功。 好的实践第一步是添加一个指向应用根 URL 的HTTP GET请求的就绪探针。 在很多情况下， 这样做就足够了。

---
### 17.3.2 在pod关闭时避免客户端断开连接
当应用接收到终止信号的时候应该如何做呢？它应该继续接收请求么？那些已经被接收但是还没有处理完毕的请求该怎么办呢？那些打开的HTTP 长连接（连接上已经没有活跃的请求了） 该怎么办呢？在回答这些问题之前， 我们需要详细地看一下当pod删除的时候， 集群中的一连串事件是如何发生的。

---
当端点控制器（在Kubernetes 的控制面板的 Controller Manager 中运行〉接收到 pod 要被删除的通知时，它从所有 pod 所在的服务中移除了这个 pod 的服务端点。它通过向 API 服务器发送 REST 请求来修改 Endpoint API 对象。 然后 API 服务器会通知所有的客户端关注这个 Endpoint 对象。其中的一些观察者都是运行在工作节点上面的 kube-proxy 服务。每个 kube-proxy 服务都会在自己的节点上更新 iptabl es 规则，以阻止新的连接被转发到这些处于停止状态的 pod 上。**这里一个重要的细节是，移除 iptables规则对己存在的连接没有影响一一已经连接到 pod 的客户端仍然可以通过这些连接向 pod 发送额外的请求。**

上面的两串事件是并行发生的。最有可能的是，关闭 pod 中应用进程所消耗的时间比完成 iptables 规则更新所需要的时间稍微短一点。

所以存在很大的可能性是SIGTERM信号会在iptables规则更新到所有的节点之前发送出去。

最终结果就是因为iptables还未更新，所以在发送SIGTERM信号后该pod还会被转入客户端连接，这回导致客户端收到“连接被拒绝一类的错误”，因为它的连接被转入了关闭的pod。

---
### 解决问题
用 Google 搜索这个问题的解决方案看上去就是给你的 pod 添加一个就绪探针来解决问题。  假设你所需要做的事情就是在 pod 接收到 SIGTERM 信号的时候就绪探针开始失败。这回导致pod从服务的EndPoint中被移除。但是这个移除动作只会在就绪探针持续性失败一段时间后才会发生（可以在就绪探针的 spec 中配置），并且这个移除动作还是需要先到达 kube-proxy 然后 iptables 规则才会移除这个 pod。

实际上，就绪探针完全不影响这个过程，端点控制器在接收到 pod 要被删除（当 pod spec 中的 deletionTimestamp 宇段不再是 null ）的通知的时候就会从Endpoint 中移除 pod 。 从那个时候开始，就绪探针的结果己经无关紧要了 。

那么这个问题的合适的解决方案是什么呢？如何保证所有的请求都被处理了呢？

很明显， pod 必须在接收到终止信号之后仍然保持接收连接（即别急着关闭pod）直到所有的 kube ­proxy 完成了 iptables 规则的更新。

这是不可能的，因为这些组件分布在不同的机器上面。即使你知道每一个组件的位置并且可以等到它们都来通知你可以关闭 pod 了，万一其中有一个组件未响应呢？这个时候，你需要等待这个回复多长时间？记住，在这个时间段内，你延阻了关闭的过程。

你可以做的唯一的合理的事情就是等待足够长的时间让所有的 kube-proxy 可以完成他们的工作。

那么多长时间才是足够的呢？在大部分场景下，几秒钟应该就足够了，但是无法保证每次都是足够的。当 API 服务器或者端点控制器过载的时候，通知到达kube-proxy 的时间会更长。 你无法完美地解决这个问题，理解这一点很重要，但是即使增加 5 秒或者 10 秒延迟也会极大提升用户体验。 可以用长一点的延迟时间，但是别太长，因为这会导致容器无法正常关闭，而且会导致 pod 被删除很长一段时间后还显示在列表里面，这个会给删除 pod 的用户带来困扰。

> 即在接收到终止信号后妥善的处理已存在和建立的连接。

至少可以添加一个停止前钩子来等待几秒钟再退出。
例如 preStop.exec.command ["sleep 5"]

---
## 17.4 让应用程序在kubernetes中方便运行和管理
即如何构建方便在 Kubemetes 中管理的应用。

---
### 17.4.1 构建可管理的容器镜像
当你把应用打包进镜像的时候，可以包括应用的二进制文件和它的依赖库，或者可以将一个完整的操作系统和应用打包在一起。很多人都会这样做， 尽管很多时候并不需要这样。

部署新的 pod 或者扩展它们会很快。 这个要求镜像足够小而且不包容任何无用的东西。如果你使用 Go 语言来构建应用，你的镜像除了应用的可执行二进制文件外不需要任何东西。 这样基于 Go 语言的容器镜像就会非常小，很适合 Kubernetes 。

> 提示： 在这些镜像的 Dockerfile 中使用 FROM scratch（从头开始） 指令。（即从最基本开始构建镜像，而不是基于某一个镜像构建）。

是在实践中，你就会发现这些最小化构建的镜像非常难以调试。 当你需要运行一些工具，例如 pinq、 dig、 curl 或者容器中其他类似的命令的时候， 你就会意识到让容器再至少包含这些工具的最小集合有多重要。

无法告诉你应该在你的镜像中包含哪些工具，不包含哪些工具，因为一切取决于你的需求，你需要自己发现最适合自己的方式。

---
### 17.4.2 合理地给镜像打标签，正确地使用ImagePullPolicy
必须使用能够指明具体版本的标签而不是 latest 。
记住如果你使用的是可更改的标签（总是向相同的标签推送更改），那么你需要在 pod spec 中将imagePullPolicy 设置为 Always 。（因为如果不设置，更改了还是使用旧的image，设置为每次使用都拉取更改过镜像）。

---
### 17.4.3 使用多维度而不是单维度的标签
别忘了给所有的资源都打上标签，而不仅仅是 pod 。确保你给每个资源添加了多个标签，这样就可以通过不同的维度来选择它们了。在资源数量飞速增长的时候，你 （或者运维团队）会感激你自己的。

### 标签可以包含以下内容：  
- 源所属的应用（或者微服务） 的名称
- 应用层级（前端、后端，等等）
- 运行环境（开发、测试、预发布、生产，等等）
- 版本号
- 发布类型（稳定版、 金丝雀、蓝绿开发中的绿色或者蓝色，等等）
- 租户 （如果你在每个租户中运行不同的 pod 而不是使用命名空间）
- 分片（带分片的系统）

标签管理可以让你以组而不是隔离的方式来管理资源，从而很容易了解资源的
归属。

---
### 17.4.4 通过注解描述每个资源
可以使用注解来给你的资源添加额外的信息。 资源至少应该包括一个描述资源的注解和一个描述资源负责人的注解。

在微服务框架中， pod 应该包含一个注解来描述该 pod 依赖的其他服务的名称。这样就很容易展现 pod 之间的依赖关系了。其他的注解可以包括构建和版本信息，以及其他工具或者图形界面会使用到的元信息（图标名称等）。

标签和注解都可以让你更加容易地管理运行中的应用，但是没有什么比应用开始崩溃而你对原因一无所知更糟糕的了。

--- 
### 17.4.5 给进程终止提供更多的信息
为了让诊断过程更容易，可以使用 Kubernetes 的另一个特性，这个特性可以在pod 状态中很容易地显示出容器终止的原因。可以让**容器中的进程**向**容器的文件系统**中指定文件写入一个终止消息。 这个文件的内容会在容器终止后**被 Kubelet 读取**，然后显示在 kubectl describe  pod 中 。

如果一个应用使用这种机制的话，操作人员无须去查看容器的日志就可以很快地看到应用为什么终止了。

这个进程需要写入终止消息的文件默认路径是／dev/termination-log，当然这个路径也可以在 pod spec 中容器定义的部分设置 terminationMessagePath 宇段来自定义。

> 注意: 如果容器没有向任何文件写入消息，可以将TerminationMessagePolicy字段的值设置为FallbackToLogsOnError。这种情况下，容器的最后几行日志会被当做终止消息。

---
### 17.4.6 处理应用日志
`kl logs`

如果应用把日志写到了文件而不是标准输出终端，那么可以使用另外一种方法来查看日志：  
`kl exec <pod> cat <logfile>`

### 将日志或者其他文件复制到容器或者从容器中赋复制出来

使用下面的命令将这个文件传送到本地机器：  
`kl cp pod_name:/var/log/200310.log 200310.log` 
将容器中的/var/log/200310.log文件复制到本地为200310.log。

将文件从你的本地机器复制到pod中， 可以指定pod的名字作为第二个参数：  
`kl cp localfile pod_name:/var/log/`

这个命令把本地文件localfile 复制到了pod的容器里面， 路径是 /var/log/。如果有多个容器，使用-c选项来指定具体容器。

---
### 使用集中式日志记录

了解了解。

---
## 17.5 开发和测试的最佳实践

---
### 17.5.1 开发过程中在 Kubernetes 之外运行应用

通常可以直接在你的IDE里面运行你的应用。

---
### 连接到后台服务
生产环境中， 如果应用连接到后台服务。不管这个后台服务是在Kubemetes里面还是外面运行。 如果这个服务在Kubemetes里面运行，总是可以（至少是临时的） 把这个服务改为NodePort或者LoadBalancer类型来让这个服务对外可访问。

---
### 连接到API服务器
同样地， 如果你的应用运行在Kubernetes集群中时需要访问Kubernetes的 API服务器， 它在开发的时候可以很容易地从集群外部访问 API服务器。 如果应用使用ServiceAccount凭证来验证自己，那么你可以把`ServiceAccount`的`Secret`文件使用`kubectl cp`命令复制到你的本地机器。 API服务器并不关心客户端的请求是来自集群内部还是外部。

---
### 在开发过程中在容器内部运行应用
如果在开发过程中， 你因为各种原因不可避免地要在容器中运行应用， 这里有个方法， 不用每次都去构建一个容器。 例如，可以总是将本地文件系统通过Docker的Volume挂载到容器中。这样， 当你给应用构建了一个新的二进制版本之后， 你所需要做的事情就是重启这个容器（在支持热部署的清况下， 甚至都不需要重启容器），不需要重新构建整个镜像。

---
### 17.5.3 发布版本和自动部署资源清单

因为Kubernetes采用的是指令式模型， 你不必判肋出部署的资源的当前状态， 然后向它们发送命令来将资源状态切换到你期望的那样。 你需要做的就是**告诉Kubernetes你希望的状态**， 然后Kubernetes 会采取相关的必要措施来将集群的状态切换到你期望的样子。

可以将资源的manifest存放到 一 个版本控制系统中， 这样可以方便做代码审查， 审计跟踪， 或者任何需要的时候回退更改。 在每次提交更改之后， 可以使用kubectl apply命令将更改反映到部署的资源中。

---