## 1.1 Kubernetes 系统的需求  

### 1.1.1 从单体应用到微服务  
单体应用由多个组件组成。这些组件紧密地耦合在一起，由于他们在同一个操作系统进程中运行，所以在开发、部署、管理的时候必须以同一个实体进行。对单体应用来说，即使是某个组件中的一个小的修改，都需要重新部署整个应用。  

**将应用拆解为多个微服务**  
这些问题迫使我们将复杂的大型单体应用，拆分为小的可独立部署的微服务组件。每个微服务以独立的进程运行，并且通过简单且定义良好的接口（API）与其他的微服务通信。  

**部署微服务**  

### 1.1.3 迈向持续交付：DevOps和无运维  
让同一个团队参与应用的开发、部署、运维的整个生命周期更好。这意味着开发者、QA和运维团队彼此之间的合作需要贯穿整个流程。这种实践被称为DevOps。  
开发者是部署程序本身，不需要和运维团队交涉，这被叫作NoOps。正如你所看到的，Kubernetes能让我们实现所有这些想法。通过对实际硬件做抽象，然后将自身暴露成一个平台，同于部署和运行应用程序。它允许开发者自己配置和部署应用程序，而不需要系统管理员的任何帮助，让系统管理员聚焦于保持底层基础设施运转正常的同时，不需要关注实际运行在平台上的应用程序。  

## 1.2 介绍容器技术  

### 1.2.1 什么是容器  
容器允许你在同一台机器上于宁多个服务，不仅提供不同的环境给每个服务，而且将他们相互隔离。容器类似虚拟机，但开销小很多。  
一个容器里运行的进程实际上运行在宿主机的操作系统上，就像所有其他进程一样（不像虚拟机，进程是运行在不同的操作系统上的）。但是容器里的进程是和其他进程隔离的。对于容器内进程本身而言，就好像是在机器和操作系统上运行的唯一一个进程。  

**比较虚拟机和容器**  
和虚拟机比较，容器更加轻量级，它允许在相同的硬件上运行更多数量的组件。主要是因为每个虚拟机需要运行自己的一组系统进程，这就产生了除组件进程消耗以外的额外计算资源损耗。从另一个方面说，一个容器仅仅是运行在宿主机上被隔离的单个进程，仅消耗应用容器消耗的资源，不会有其他进程的开销。  

虚拟机的主要好处是他们提供完全隔离的环境，每个虚拟机运行在它自己的内核上，而容器都是调用同一个内核。这自然会有安全隐患。每个虚拟机运行属于自己的系统服务，而容器不会，因为他们都运行在同一个操作系统上，那也就意味着运行一个容器不用像虚拟机那样开机，它的进程很快就可以启动。  

**容器实现隔离机制介绍**  
你可能会好奇，如果多个进程运行在同一个操作系统上，那容器到底是怎样隔离它们的。有两个机制可用：第一个是Linux命名空间，它使每个进程只看到自己的系统视图（文件、进程、网络接口、主机名）；第二个是Linux控制组（cgroups），它限制了进程能够使用的资源量（CPU、内存、网络带宽等。）  

### 1.2.2 Docker容器平台介绍

**Docker的概念**  
Docker是一个打包、分发和运行应用程序的平台。  

三个概念组成了这种情形：  
+ 镜像 — Docker镜像里包含了你打包的应用程序及其所依赖的环境。它包含应用程序可用的文件系统和其他元数据。如镜像运行时的可执行文件路径。  
+ 镜像仓库 — Docker镜像仓库用于存放Docker镜像，以及促进不同人和不同电脑之间共享这些镜像。仓库有公共仓库和私有仓库。  
+ 容器 — Docker容器通常是一个Linux容器，它基于Docker镜像被创建。一个运行中的容器是一个运行在Docker主机上的进程，但它和主机，以及所有运行在主机上的其他进程都是隔离的。这个进程也是资源受限的，意味着它只能访问和使用分配给它的资源（cpu、内存、网络接口等）。  

**构建、分发和运行Docker镜像**  
流程大致可以如下：开发人员构建一个镜像，然后将镜像推送到镜像仓库，然后其他人可以将镜像拉取到任何运行着Docker的机器上，然后Docker会基于镜像创建一个独立的容器，并运行二进制可执行文件。  

在虚拟机中，应用A和应用B看到的是相同的文件系统。  

**镜像层**  
Docker镜像由多层构成。不同镜像可能包含完全相同的层，因为这些Docker镜像都是基于另一个镜像之上构建的，不同的镜像都能使用相同的父镜像作为他们的基础镜像。这提升了镜像在网络上的分发效率，当传输某个镜像时，因为相同的层已被之前的镜像传输，那么这些层就不需要再被传输。  
层不仅使分发更加高效，也有助于减少镜像的存储空间。每一层仅被存一次，当机遇相同基础层的镜像被创建成两个容器时，他们就能读相同的文件。但是如果其中一个容器写入某些文件，另外一个是无法看见文件变更的。因此，即使他们共享文件，仍然彼此隔离。这是因为容器镜像层是只读的。容器运行时，一个新的可写层在镜像层上被创建。容器容器中进程写入位于底层的一个文件时，此文件的一个拷贝在顶层被创建，，进程写的是此拷贝。（写时复制系统）  

**容器镜像可移植性的限制**  
理论上，一个容器能运行在任何一个运行Docker的机器上。但有一个小警告——一个关于运行在一台机器上的所有共享容器共享主机Linux内核的警告。如果一个容器化的应用需要一个特定的内核版本，那它可能不能再每台机器上都能工作。如果一台机器上运行了一个不匹配的Linux版本，或者没有相同内核模块可用，那么此应用就不能再其上运行。  
还不仅仅是内核的问题。一个在特定硬件架构上编译的容器化应用，只能在有相同硬件架构的机器上运行。例如x86编译的容器，不能再ARM架构上运行。  

### 1.2.3 rkt——一个Docker的替代方案
和Docker一样，rkt也是一个运行容器的平台，，它强调安全性，可构建性并遵从开放标准。  

## 1.3 Kubernetes介绍
随着系统可部署组件的数量增长，把他们都管理起来会变得越来越困难。需要一个更好的方式来部署和管理这些组件。而且在如此海量规模下，不得不处理部署管理的问题。  

### 1.3.1 初衷

### 1.3.2 深入浅出地了解Kubernetes
Kubernetes是一个软件系统，它允许你在其上很容易地部署和管理容器化的应用。Kubernetes使你在数以千计的电脑节点上运行软件时就像所有这些节点是单个大节点一样。它将底层基础设施抽象，这样做同时简化了应用的开发、部署，以及对开发和运维团队的管理。  
通过Kubernetes部署应用程序时，你的集群包含多少节点都是一样的。集群规模不会造成什么差异性，额外的集群节点只是代表一些额外的可用来部署应用的资源。  

**Kubernetes的核心功能**  
整个系统由一个主节点和若干个工作结点组成。开发者把一个应用列表提交到主节点，Kubernetes会将他们部署到集群的工作
节点。组件被部署在哪个节点对于开发者和系统管理员来说都不用关心。  


开发者能指定一些应用必须一起运行，Kubernetes将会在一个工作节点部署它们。其他的将被分散部署都集群中，但是不管部署在哪儿，它们都能以相同的方式互相通信。  

**帮助开发者聚焦核心应用功能**  
Kubernetes可以被当做集群的一个操作系统来看待。它降低了开发者不得不在它们的应用里实现一些和基础设施相关服务的心智负担。现在依赖Kubernetes来提供这些服务，包括服务发现、扩容、负载均衡、自恢复，甚至领导者的选举。  

**帮助运维团队获取更高的资源利用率**  
Kubemetes 将你的容器化应用运行在集群的某个地方，井提供信息给应用组 
件来发现彼此并保证它们的运行。因为你的应用程序不关心它运行在哪个节点上，Kubemetes 能在任何时间迁移应用并通过混合和匹配应用来获得比手动调度高很多的资源利用率。  

### 1.3.3 Kubernetes集群架构

我们以上帝视角看到了Kubernetes的架构，现在让我们近距离看一下Kubernetes集群由什么组成。在硬件级别，一个Kubernetes集群由很多节点组成，这些节点被分成以下两种类型：  
- 主节点，它承载着Kubernetes控制和管理整个集群系统的控制面板。  
* 工作节点，他们运行用户实际部署的应用。  

**控制面板**  
控制面板用于控制集群并使它工作。它包含多个组件，组件可以运行在单个主节点上或者通过副本分别部署在多个主节点以确保高可用性。这些组件是：  
+ **Kubernetes API**服务器，你和其他控制面板组件组件都要和它通信。  
+ **Schedculer**，它调度你的应用（为应用的每个可部署组件分配一个工作节点）。  
+ **Controller Manager**，它执行集群级别的功能，如复制组件、持续跟踪工作节点、处理节点失败。  
+ etcd，一个可靠的分布式数据存储，它能持久化存储集群配置控制面板的组件持有并控制集群状态，但是他们不运行你的应用程序。这是由工作节点完成的。  

**工作节点**  
工作节点是运行容器化应用的机器。运行、监控和管理应用服务的任务是由以下组件完成的：  
* Docker、rtk或其他容器类型。  
* Kubelet，它与API服务器通信，并管理它所在节点的容器  
* Kubernetes Service Proxy（ku-be-proxy）,它负责组件之间的负载均衡网络流量。  

### 1.3.4 在Kubernetes中运行应用  

配合下图，然后更好地理解如何在Kubernetes中部署应用程序。  
![部署容器化应用](https://haochen233.oss-cn-beijing.aliyuncs.com/%E5%9B%BE%E5%BA%8A/%E5%A6%82%E4%BD%95%E5%9C%A8Kubernetes%E4%B8%AD%E9%83%A8%E7%BD%B2%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F.png?Expires=1581584989&OSSAccessKeyId=TMP.hjb6aP6cQNsQac4XCykJfJkYGcaGuCdyU3VUXyDgzvLbcUbgHYjpB2ggE6pzpC4uxvYgELUjwR7RVdaipZoW5afz2ybjkzbjfXZakv5mMo1rhvHBk9NsbSAES18AUa.tmp&Signature=YY6jxQJ3VZtcIid1bemN7QQNDok%3D)  
应用描述符列出了四个容器，并将他们分为三组（这些集合被称为pod）。前两个pod只有包含个容器，而最后一个包含了两个容器。这意味这两个容器都需要协作运行，不应该相互隔离。在每个pod旁还可以看到一个数组，表示需要并行运行的pod的副本数量。整个部署流程如下：  
1. 开发人员打包好镜像后，将镜像推送到镜像仓库。

2. 然后再向**Kubernetes**提交应用描述。

3. 在向**Kubernetes**提交应用描述符之后，它将每个**pod**的指定副本数量调度到可用的工作节点上。

4. 节点上的**Kubelets**将告知**Docker**从镜像仓库中拉取相应地镜像并运行容器。  

**保持容器运行**  
一旦应用程序运行起来，Kubernetes就会不断地确认应用程序的部署状态始终与你提供的描述相匹配。例如，如果你指出你需要运行五个web服务器实例，那么Kubernetes总是保持正好运行五个实例。如果实例之一停止了正常工作，比如当进程崩溃或停止响应时，Kubernetes将自动重启它。  
同理，如果整个工作节点死亡或无法访问，Kubernetes将为在故障节点上运行的所有容器选择新节点，并在新选择的节点上运行它们。  

**扩展副本数量**  
当应用程序运行时，可以决定要增加或减少副本量，而Kubernetes将分别增加附加的或停止多余的副本。甚至可以把决定最佳副本数目的工作交给Kubernetes。它可以根据实时指标（CPU负载、内存消耗。。。）自动调整副本数。  

**命中移动目标**  
Kubernetes可能需要在集群中迁移你的容器。当它们运行的节点失败时，或者为了给其他容器腾出地方而从节点移除时，就会发生这种情况。  
那么容器可能会迁移的情况下，容器如何被频繁调度呢？，当这些容器被复制并分布在整个集群中时，客户端如何连接到提供服务的容器呢？  
为了让客户端能够轻松找到提供特定服务的容器，可以告诉Kubernetes哪些容器提供相同的服务，而Kubernetes将通过一个静态IP地址暴露所有容器，并将该地址暴露给集群中运行的所有应用程序。这是通过环境变量完成的，但是客户端也可以通过良好的DNS查找服务IP。kube-proxy将确保到服务的连接可跨提供服务的容器实现负载均衡。服务的IP地址保持不变，因此客户端始终可以连接到它的容器，即使它们在集群中移动。  

### 1.3.5 使用Kubernetens的好处
在任何部署Kubernetes的节点上，Kubernetes可以不需要系统管理员任何帮助的情况下立即运行应用程序。  
因为容器化的应用程序已经包含了运行所需的所有内容，系统管理员不需要安装任何东西来部署和运行应用程序。  

**简化应用程序部署**  
实际上，现在所有节点都是一组等待应用程序使用他们的计算资源。开发人员通常不关心应用程序运行在哪个服务器上，只要服务器能够为应用程序提供足够的系统资源即可。  

**更好的利用硬件**  
当你告诉Kubernetes运行你的应用程序时，你在让它根据应用程序的资源需求描述 和 每个节点上的可用资源 选择最适合的节点来运行你的应用程序。  
通过使用容器，不再把这个应用绑定到一个特定的集群节点，而允许应用程序在任何时候都在集群中自由迁移，所以在集群上运行的不同应用程序组件可以被混合和匹配来紧密打包到集群节点。这将确保节点的硬件资源得到尽可能好的利用。  
可以随时在集群中移动应程序的能力，使得Kubernetes可以比人工更好地利用基础设施。  
人类不擅长寻找最优的组合，尤其是当所有选项的数量都很大时，比如当你有许多应用程序组件和许多服务器节点时，所有的组件可以部署在所有的节点上。显然，计算机可以比人类更好、更快地完成这项工作。  

**自动扩容**  
使用Kubernetes来管理部署的应用程序，也意味着运维团队不需要不断地监控单个应用程序的负载，以对突发负载峰值做出反应。 可以告诉Kubernetes监视每个应用程序使用的资源，并不断调整每个应用程序的运行实例数量。  
如果Kubernetes运行唉云基础设施上，在这些基础设施中，添加额外的节点就像通过云供应商的API请求一样简单，Kubernetes甚至可以根据部署的应用程序的需要自动地将整个集群规模放大或缩小。  

**健康检查和自修复**  
Kubernetes监控你的应用程序组件和他们运行的节点，并在节点出现故障时自动将他们重新调度到其他节点。  
这样只要你的基础设施有足够的备用资源来允许正常额系统运行，即使故障节点没有恢复，运维团队甚至不需要立即对故障做出反应。比如凌晨3点，可以等到正常的工作时间在处理，因为会将故障节点的所有容器迁移到新的节点运行。  